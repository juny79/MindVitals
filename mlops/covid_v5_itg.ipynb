{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7316c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: mlflow in /opt/conda/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: mlflow-skinny==3.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.4.0)\n",
      "Requirement already satisfied: mlflow-tracing==3.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.4.0)\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.16.5)\n",
      "Requirement already satisfied: cryptography<46,>=43.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (45.0.7)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: fastmcp<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.12.3)\n",
      "Requirement already satisfied: graphene<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/conda/lib/python3.10/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: pyarrow<22,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (21.0.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.0.43)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (8.3.0)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (0.66.0)\n",
      "Requirement already satisfied: fastapi<1 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (0.117.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (1.37.0)\n",
      "Requirement already satisfied: packaging<26 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (23.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (6.32.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (2.11.9)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (1.1.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (2.31.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (4.15.0)\n",
      "Requirement already satisfied: uvicorn<1 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.4.0->mlflow) (0.37.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (2.0.1)\n",
      "Requirement already satisfied: cffi>=1.14 in /opt/conda/lib/python3.10/site-packages (from cryptography<46,>=43.0.0->mlflow) (1.15.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (2.40.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.16)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<1->mlflow-skinny==3.4.0->mlflow) (0.48.0)\n",
      "Requirement already satisfied: authlib>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from fastmcp<3,>=2.0.0->mlflow) (1.6.4)\n",
      "Requirement already satisfied: cyclopts>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from fastmcp<3,>=2.0.0->mlflow) (3.24.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from fastmcp<3,>=2.0.0->mlflow) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from fastmcp<3,>=2.0.0->mlflow) (0.28.1)\n",
      "Requirement already satisfied: mcp<2.0.0,>=1.12.4 in /opt/conda/lib/python3.10/site-packages (from fastmcp<3,>=2.0.0->mlflow) (1.14.1)\n",
      "Requirement already satisfied: openapi-core>=0.19.5 in /opt/conda/lib/python3.10/site-packages (from fastmcp<3,>=2.0.0->mlflow) (0.19.5)\n",
      "Requirement already satisfied: openapi-pydantic>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from fastmcp<3,>=2.0.0->mlflow) (0.5.1)\n",
      "Requirement already satisfied: pyperclip>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from fastmcp<3,>=2.0.0->mlflow) (1.10.0)\n",
      "Requirement already satisfied: rich>=13.9.4 in /opt/conda/lib/python3.10/site-packages (from fastmcp<3,>=2.0.0->mlflow) (14.1.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (2.1.1)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.4.0->mlflow) (3.23.0)\n",
      "Requirement already satisfied: anyio>=4.5 in /opt/conda/lib/python3.10/site-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (4.11.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /opt/conda/lib/python3.10/site-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /opt/conda/lib/python3.10/site-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (4.20.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /opt/conda/lib/python3.10/site-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (3.0.2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (0.6.1)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (1.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn<1->mlflow-skinny==3.4.0->mlflow) (0.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.14->cryptography<46,>=43.0.0->mlflow) (2.21)\n",
      "Requirement already satisfied: attrs>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (23.1.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /opt/conda/lib/python3.10/site-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (0.17.0)\n",
      "Requirement already satisfied: rich-rst<2.0.0,>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (1.3.1)\n",
      "Requirement already satisfied: docutils in /opt/conda/lib/python3.10/site-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (0.22.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (1.0.9)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.13.2)\n",
      "Requirement already satisfied: isodate in /opt/conda/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (0.7.2)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (8.12.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (0.7.2)\n",
      "Requirement already satisfied: parse in /opt/conda/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (1.20.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (0.4.4)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (1.12.0)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow) (2.3.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow) (2.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas scikit-learn mlflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e52082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /opt/conda/lib/python3.10/site-packages (from xgboost) (2.28.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.11.3)\n",
      "Using cached xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ffc667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auto] Using fallback file: ./covid_processed.csv\n",
      "[info] Using table file: ./covid_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 08:09:54 INFO mlflow.tracking.fluent: Experiment with name 'covid_model_training_integrated' does not exist. Creating a new experiment.\n",
      "2025/09/26 08:09:55 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLflow] Fallback to file:/root/mlruns. Model registry disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:213: LinAlgWarning: Ill-conditioned matrix (rcond=3.22951e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE. Best: random_forest Test metrics: {'rmse': 0.001485120418831939, 'mae': 0.0014851204188319391, 'r2': 0.0, 'mape': 148512046.0834014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Robust Integrated Covid Trainer (MLflow server fallback safe)\n",
    "\n",
    "- MLflow 서버가 없으면 자동으로 file:/root/mlruns 로 폴백 (레지스트리 비활성)\n",
    "- CSV/TSV/Excel 로더(구분자/인코딩 견고화 + 잘못된 경로 자동 보정)\n",
    "- 최소 FE(시간/주기 + lag/roll/diff/pct) 자동 생성 -> 미래 피처 화이트리스트 통과\n",
    "- 최근 N일 고정 평가 + (옵션)TS CV\n",
    "- 동적 재귀 예측(H-step)\n",
    "- 베스트 모델 저장(레지스트리 가능 시 등록, 불가 시 아티팩트 저장)\n",
    "\n",
    "pip install numpy pandas scikit-learn mlflow matplotlib\n",
    "# (optional) pip install xgboost\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, glob, json, math, argparse, tempfile\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "\n",
    "# ========================= MLflow Safe Init =========================\n",
    "\n",
    "def setup_mlflow_or_fallback(experiment_name: str, preferred_uri: Optional[str] = None) -> bool:\n",
    "    \"\"\"\n",
    "    1) preferred_uri (또는 환경변수 MLFLOW_TRACKING_URI)가 있으면 먼저 시도\n",
    "    2) 연결/권한/유효성 실패 시 file:/root/mlruns 로 폴백\n",
    "    반환값: registry_enabled (True면 레지스트리 사용 가능, False면 아티팩트 저장만)\n",
    "    \"\"\"\n",
    "    uri = preferred_uri or os.getenv(\"MLFLOW_TRACKING_URI\", \"\").strip() or None\n",
    "\n",
    "    def try_uri(u: str) -> bool:\n",
    "        try:\n",
    "            mlflow.set_tracking_uri(u)\n",
    "            # 간단한 호출로 연결성 점검\n",
    "            _ = mlflow.get_experiment_by_name(experiment_name)\n",
    "            mlflow.set_experiment(experiment_name)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    # 1) 사용자가 지정한 URI 먼저 시도 (HTTP/HTTPS/File 모두 허용)\n",
    "    if uri and try_uri(uri):\n",
    "        # 레지스트리 사용 가능 여부 판정:\n",
    "        # - HTTP(S)인 경우 대체로 가능, file: 인 경우 대체로 불가\n",
    "        reg_enabled = uri.startswith(\"http\")\n",
    "        if not reg_enabled:\n",
    "            print(f\"[MLflow] Using '{uri}' (file store). Model registry disabled.\")\n",
    "        else:\n",
    "            print(f\"[MLflow] Connected to '{uri}'. Model registry enabled.\")\n",
    "        return reg_enabled\n",
    "\n",
    "    # 2) 폴백: 로컬 파일 스토어\n",
    "    local_dir = \"/root/mlruns\"\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "    local_uri = f\"file:{local_dir}\"\n",
    "    mlflow.set_tracking_uri(local_uri)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    print(f\"[MLflow] Fallback to {local_uri}. Model registry disabled.\")\n",
    "    return False\n",
    "\n",
    "\n",
    "# ========================= Robust Loader =========================\n",
    "\n",
    "DEFAULT_CANDIDATES = [\n",
    "    \"/mnt/data/covid_processed.csv\",\n",
    "    \"./covid_processed.csv\",\n",
    "    \"./data/covid_processed.csv\",\n",
    "    \"./dataset/covid_processed.csv\",\n",
    "]\n",
    "\n",
    "def _read_head_bytes(path: str, nbytes: int = 2048) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw = f.read(nbytes)\n",
    "    for enc in (\"utf-8\",\"utf-8-sig\",\"cp949\",\"euc-kr\",\"latin1\"):\n",
    "        try:\n",
    "            return raw.decode(enc, errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return raw.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def _looks_like_json(text_head: str) -> bool:\n",
    "    s = text_head.strip()\n",
    "    return (s.startswith(\"{\") and \":\" in s) or (s.startswith(\"[\") and \"{\" in s)\n",
    "\n",
    "def resolve_table_path(path: str) -> str:\n",
    "    \"\"\"경로가 파일이 아니거나 JSON이어도 CSV/TSV/Excel을 최대한 찾아 반환.\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        if os.path.isdir(path):\n",
    "            for pat in (\"*.csv\",\"*.tsv\",\"*.xlsx\",\"*.xls\"):\n",
    "                m = glob.glob(os.path.join(path, pat))\n",
    "                if m: return m[0]\n",
    "            raise FileNotFoundError(f\"No table file found in directory: {path}\")\n",
    "        else:\n",
    "            head = _read_head_bytes(path)\n",
    "            if not _looks_like_json(head):\n",
    "                return path\n",
    "            # JSON이면 계속 폴백 진행\n",
    "\n",
    "    for cand in DEFAULT_CANDIDATES:\n",
    "        if os.path.exists(cand):\n",
    "            head = _read_head_bytes(cand)\n",
    "            if not _looks_like_json(head):\n",
    "                print(f\"[auto] Using fallback file: {cand}\")\n",
    "                return cand\n",
    "\n",
    "    for pat in (\"*.csv\",\"*.tsv\",\"*.xlsx\",\"*.xls\"):\n",
    "        for m in glob.glob(pat):\n",
    "            head = _read_head_bytes(m)\n",
    "            if not _looks_like_json(head):\n",
    "                print(f\"[auto] Using discovered file: {m}\")\n",
    "                return m\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not locate a valid table file. Tried '{path}' and fallbacks: {DEFAULT_CANDIDATES}\"\n",
    "    )\n",
    "\n",
    "def read_table_robust(path: str) -> pd.DataFrame:\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext in {\".xlsx\",\".xls\"}:\n",
    "        return pd.read_excel(path)\n",
    "\n",
    "    # auto-sep\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=None, engine=\"python\")\n",
    "        if len(df.columns) > 1: return df\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # enc × sep 재시도\n",
    "    for enc in (\"utf-8\",\"utf-8-sig\",\"cp949\",\"euc-kr\",\"latin1\"):\n",
    "        for sep in (\"\\t\",\",\",\";\",\"|\"):\n",
    "            try:\n",
    "                df = pd.read_csv(path, sep=sep, engine=\"python\", encoding=enc)\n",
    "                if len(df.columns) > 1: return df\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    # 단일 컬럼 분해 시도\n",
    "    try:\n",
    "        df = pd.read_csv(path, engine=\"python\", encoding=\"utf-8\", header=None)\n",
    "        if len(df.columns) == 1:\n",
    "            series = df.iloc[:,0].astype(str)\n",
    "            if series.str.contains(\"\\t\").any():\n",
    "                return series.str.split(\"\\t\", expand=True)\n",
    "            if series.str.contains(\",\").any():\n",
    "                return series.str.split(\",\", expand=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    head = _read_head_bytes(path)\n",
    "    raise ValueError(f\"Failed to parse table file. Head: {head[:200]} ...\")\n",
    "\n",
    "\n",
    "# ========================= Minimal FE =========================\n",
    "\n",
    "DATE_FEATS = [\"dow_sin\",\"dow_cos\",\"weekofyear\",\"dayofyear\",\"month_sin\",\"month_cos\"]\n",
    "\n",
    "def add_time_features(df: pd.DataFrame, date_col=\"date\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if date_col not in df.columns:\n",
    "        for cand in [\"Date\",\"ds\",\"DATE\",\"날짜\"]:\n",
    "            if cand in df.columns:\n",
    "                df.rename(columns={cand:\"date\"}, inplace=True)\n",
    "                break\n",
    "    if \"date\" not in df.columns:\n",
    "        raise ValueError(\"Missing 'date' column after rename attempts.\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    if df[\"date\"].isna().all():\n",
    "        raise ValueError(\"All 'date' values failed to parse. Check date format.\")\n",
    "    df[\"dow\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"weekofyear\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "    df[\"dayofyear\"] = df[\"date\"].dt.dayofyear\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dow\"]/7);  df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dow\"]/7)\n",
    "    df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12); df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "    return df\n",
    "\n",
    "def add_lag_roll(df: pd.DataFrame, target: str, lags=(1,7,14), rolls=(7,14,28)) -> pd.DataFrame:\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target '{target}' not found.\")\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    for l in lags:\n",
    "        df[f\"{target}_lag{l}\"] = df[target].shift(l)\n",
    "    for w in rolls:\n",
    "        df[f\"{target}_rollmean{w}\"] = df[target].shift(1).rolling(w, min_periods=1).mean()\n",
    "        df[f\"{target}_rollstd{w}\"]  = df[target].shift(1).rolling(w, min_periods=1).std()\n",
    "    df[f\"{target}_diff1\"] = df[target].diff(1)\n",
    "    df[f\"{target}_pct\"]   = df[target].pct_change().replace([np.inf,-np.inf], np.nan)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[num_cols] = df[num_cols].interpolate(\"linear\", limit_direction=\"both\")\n",
    "    df = df.bfill().ffill()\n",
    "    return df\n",
    "\n",
    "def select_future_aware_features(df: pd.DataFrame, target: str) -> List[str]:\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    allowed = []\n",
    "    for c in num_cols:\n",
    "        if c in DATE_FEATS or c.startswith(f\"{target}_\"):\n",
    "            allowed.append(c)\n",
    "    allowed = [c for c in allowed if c not in {target,\"y_next\"} and c in df.columns]\n",
    "    return sorted(list(dict.fromkeys(allowed)))\n",
    "\n",
    "\n",
    "# ========================= Plots =========================\n",
    "\n",
    "def _lineplot(dates, series, title, fname):\n",
    "    fig = plt.figure(); plt.plot(dates, series)\n",
    "    plt.title(title); plt.xlabel(\"date\"); plt.ylabel(\"value\")\n",
    "    mlflow.log_figure(fig, fname); plt.close(fig)\n",
    "\n",
    "def _dualplot(dates, y_true, y_pred, title, fname):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(dates, y_true, label=\"actual\")\n",
    "    plt.plot(dates, y_pred, label=\"pred\")\n",
    "    plt.legend(); plt.title(title); plt.xlabel(\"date\"); plt.ylabel(\"value\")\n",
    "    mlflow.log_figure(fig, fname); plt.close(fig)\n",
    "\n",
    "def _residplot(y_true, y_pred, title, fname):\n",
    "    res = np.array(y_true) - np.array(y_pred)\n",
    "    fig = plt.figure(); plt.scatter(y_pred, res, s=8); plt.axhline(0)\n",
    "    plt.title(title); plt.xlabel(\"pred\"); plt.ylabel(\"residuals\")\n",
    "    mlflow.log_figure(fig, fname); plt.close(fig)\n",
    "\n",
    "\n",
    "# ========================= Dynamic Forecast =========================\n",
    "\n",
    "def _roll_stats(seq: List[float], w: int) -> Tuple[float,float]:\n",
    "    arr = np.array(seq[-w:], dtype=float)\n",
    "    return float(np.mean(arr)), float(np.std(arr, ddof=0))\n",
    "\n",
    "def _date_feats(ts: pd.Timestamp) -> Dict[str,float]:\n",
    "    dow = ts.dayofweek\n",
    "    weekofyear = int(ts.isocalendar().week)\n",
    "    dayofyear = int(ts.timetuple().tm_yday)\n",
    "    month = int(ts.month)\n",
    "    return {\n",
    "        \"dow_sin\": math.sin(2*math.pi*dow/7.0),\n",
    "        \"dow_cos\": math.cos(2*math.pi*dow/7.0),\n",
    "        \"weekofyear\": float(weekofyear),\n",
    "        \"dayofyear\": float(dayofyear),\n",
    "        \"month_sin\": math.sin(2*math.pi*month/12.0),\n",
    "        \"month_cos\": math.cos(2*math.pi*month/12.0),\n",
    "    }\n",
    "\n",
    "def recursive_forecast_dynamic(df_feat: pd.DataFrame, target: str,\n",
    "                               feat_list: List[str], model, horizon: int,\n",
    "                               lookbacks: List[int], rolls: List[int]) -> pd.DataFrame:\n",
    "    df = df_feat.sort_values(\"date\").copy()\n",
    "    last_date = pd.to_datetime(df[\"date\"].max())\n",
    "    hist = df[target].astype(float).tolist()\n",
    "    preds, dates = [], []\n",
    "    for i in range(1, horizon+1):\n",
    "        nd = last_date + pd.Timedelta(days=i)\n",
    "        row: Dict[str,float] = {}\n",
    "        row.update(_date_feats(nd))\n",
    "        for l in lookbacks:\n",
    "            row[f\"{target}_lag{l}\"] = float(hist[-l]) if len(hist) >= l else float(hist[-1])\n",
    "        for w in rolls:\n",
    "            m,s = _roll_stats(hist, min(len(hist), w))\n",
    "            row[f\"{target}_rollmean{w}\"] = m\n",
    "            row[f\"{target}_rollstd{w}\"] = s\n",
    "        if len(hist) >= 2:\n",
    "            diff1 = hist[-1] - hist[-2]\n",
    "            base = hist[-2] if hist[-2] != 0 else 1e-9\n",
    "            pct = (hist[-1] - base) / max(abs(base), 1e-9)\n",
    "        else:\n",
    "            diff1, pct = 0.0, 0.0\n",
    "        row[f\"{target}_diff1\"] = float(diff1)\n",
    "        row[f\"{target}_pct\"]   = float(pct)\n",
    "        x = np.array([[row.get(c,0.0) for c in feat_list]], dtype=np.float32)\n",
    "        yhat = float(model.predict(x)[0])\n",
    "        preds.append(yhat); dates.append(nd); hist.append(yhat)\n",
    "    return pd.DataFrame({\"date\": dates, \"yhat\": preds})\n",
    "\n",
    "\n",
    "# ========================= Metrics =========================\n",
    "\n",
    "def _metrics(y_true, y_pred) -> Dict[str,float]:\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    r2   = float(r2_score(y_true, y_pred))\n",
    "    mape = float(np.mean(np.abs((y_true - y_pred)/np.maximum(1e-9, np.abs(y_true))))*100.0)\n",
    "    return {\"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"mape\": mape}\n",
    "\n",
    "\n",
    "# ========================= Trainer =========================\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    experiment_name: str = \"covid_model_training_integrated\"\n",
    "    target_col: str = \"new_cases\"\n",
    "    test_days: int = 60\n",
    "    horizon: int = 30\n",
    "    lookbacks: List[int] = None\n",
    "    rolls: List[int] = None\n",
    "    do_time_series_cv: bool = True\n",
    "    cv_splits: int = 3\n",
    "    random_state: int = 42\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.lookbacks is None: self.lookbacks = [1,7,14]\n",
    "        if self.rolls is None:     self.rolls     = [7,14,28]\n",
    "\n",
    "class IntegratedCovidTrainer:\n",
    "    def __init__(self, cfg: Optional[TrainConfig] = None, tracking_uri: Optional[str] = None):\n",
    "        self.cfg = cfg or TrainConfig()\n",
    "        # 안전한 초기화 (서버 없으면 파일 모드로 자동 폴백)\n",
    "        self.registry_enabled = setup_mlflow_or_fallback(self.cfg.experiment_name, tracking_uri)\n",
    "\n",
    "        self.models: Dict[str,Any] = {\n",
    "            \"random_forest\": RandomForestRegressor(random_state=self.cfg.random_state, n_estimators=400, max_depth=12, min_samples_leaf=2, n_jobs=-1),\n",
    "            \"gradient_boosting\": GradientBoostingRegressor(random_state=self.cfg.random_state, n_estimators=300, learning_rate=0.05, max_depth=3),\n",
    "            \"linear_regression\": LinearRegression(),\n",
    "            \"ridge_regression\": Ridge(random_state=self.cfg.random_state),\n",
    "        }\n",
    "        try:\n",
    "            from xgboost import XGBRegressor\n",
    "            self.models[\"xgboost\"] = XGBRegressor(\n",
    "                n_estimators=600, max_depth=6, learning_rate=0.05, subsample=0.9,\n",
    "                colsample_bytree=0.9, reg_lambda=1.0, tree_method=\"hist\",\n",
    "                random_state=self.cfg.random_state, n_jobs=-1\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    def train(self, df_feat: pd.DataFrame, target: str) -> Dict[str,Any]:\n",
    "        with mlflow.start_run(run_name=\"model_training_integrated\"):\n",
    "            if \"date\" not in df_feat.columns:\n",
    "                raise ValueError(\"features_df must include 'date' column\")\n",
    "\n",
    "            feat_list = select_future_aware_features(df_feat, target)\n",
    "            if not feat_list:\n",
    "                raise ValueError(\"No future-aware features. FE must add lag/roll/diff/pct and date features.\")\n",
    "            mlflow.log_text(\"\\n\".join(feat_list), \"features_used.txt\")\n",
    "\n",
    "            df = df_feat.sort_values(\"date\").copy()\n",
    "            df[\"y_next\"] = df[target].shift(-1)\n",
    "            df = df.dropna(subset=[\"y_next\"]).reset_index(drop=True)\n",
    "            X_all = df[feat_list].astype(np.float32)\n",
    "            y_all = df[\"y_next\"].astype(np.float32)\n",
    "            dt_all = pd.to_datetime(df[\"date\"]).reset_index(drop=True)\n",
    "\n",
    "            cutoff = dt_all.max() - pd.Timedelta(days=self.cfg.test_days-1)\n",
    "            train_mask = dt_all < cutoff\n",
    "            test_mask  = ~train_mask\n",
    "            X_train, X_test = X_all[train_mask].reset_index(drop=True), X_all[test_mask].reset_index(drop=True)\n",
    "            y_train, y_test = y_all[train_mask].reset_index(drop=True), y_all[test_mask].reset_index(drop=True)\n",
    "            dt_train, dt_test = dt_all[train_mask].reset_index(drop=True), dt_all[test_mask].reset_index(drop=True)\n",
    "\n",
    "            mlflow.log_params({\n",
    "                \"target\": target,\n",
    "                \"test_days\": self.cfg.test_days,\n",
    "                \"horizon\": self.cfg.horizon,\n",
    "                \"lookbacks\": \",\".join(map(str,self.cfg.lookbacks)),\n",
    "                \"rolls\": \",\".join(map(str,self.cfg.rolls)),\n",
    "                \"train_rows\": len(X_train),\n",
    "                \"test_rows\": len(X_test),\n",
    "                \"feature_count\": len(feat_list),\n",
    "                \"models\": list(self.models.keys()),\n",
    "            })\n",
    "\n",
    "            results: Dict[str,Any] = {}\n",
    "            for name, model in self.models.items():\n",
    "                try:\n",
    "                    model.fit(X_train, y_train)\n",
    "                    ytr = model.predict(X_train)\n",
    "                    yte = model.predict(X_test)\n",
    "                    m_tr = _metrics(y_train, ytr)\n",
    "                    m_te = _metrics(y_test, yte)\n",
    "                    for k,v in m_tr.items(): mlflow.log_metric(f\"{name}_train_{k}\", v)\n",
    "                    for k,v in m_te.items(): mlflow.log_metric(f\"{name}_test_{k}\",  v)\n",
    "\n",
    "                    if self.cfg.do_time_series_cv:\n",
    "                        try:\n",
    "                            tscv = TimeSeriesSplit(n_splits=self.cfg.cv_splits)\n",
    "                            cv = cross_val_score(model, X_train, y_train, cv=tscv, scoring=\"neg_root_mean_squared_error\")\n",
    "                            mlflow.log_metric(f\"{name}_cv_rmse_mean\", float((-cv).mean()))\n",
    "                            mlflow.log_metric(f\"{name}_cv_rmse_std\",  float((-cv).std()))\n",
    "                        except Exception:\n",
    "                            pass\n",
    "\n",
    "                    _dualplot(dt_test, y_test, yte, f\"{name}: actual vs pred (test)\", f\"{name}_test_pred.png\")\n",
    "                    _residplot(y_test, yte, f\"{name}: residuals (test)\", f\"{name}_test_resid.png\")\n",
    "\n",
    "                    results[name] = {\"model\": model, \"metrics\": {\"train\": m_tr, \"test\": m_te}, \"pred\": {\"train\": ytr, \"test\": yte}}\n",
    "                except Exception as e:\n",
    "                    mlflow.log_text(str(e), f\"{name}_error.txt\")\n",
    "\n",
    "            if not results:\n",
    "                raise RuntimeError(\"No models trained successfully.\")\n",
    "\n",
    "            best = min(results, key=lambda n: results[n][\"metrics\"][\"test\"][\"rmse\"])\n",
    "            best_model = results[best][\"model\"]\n",
    "            mlflow.log_param(\"best_model_name\", best)\n",
    "            mlflow.log_metric(\"best_model_test_rmse\", results[best][\"metrics\"][\"test\"][\"rmse\"])\n",
    "            mlflow.log_metric(\"best_model_test_r2\",   results[best][\"metrics\"][\"test\"][\"r2\"])\n",
    "\n",
    "            # comparison\n",
    "            comp = {}\n",
    "            for n,r in results.items():\n",
    "                comp[n] = {\n",
    "                    \"test_rmse\": r[\"metrics\"][\"test\"][\"rmse\"],\n",
    "                    \"test_mae\":  r[\"metrics\"][\"test\"][\"mae\"],\n",
    "                    \"test_r2\":   r[\"metrics\"][\"test\"][\"r2\"],\n",
    "                    \"train_rmse\": r[\"metrics\"][\"train\"][\"rmse\"],\n",
    "                    \"train_r2\":   r[\"metrics\"][\"train\"][\"r2\"],\n",
    "                }\n",
    "            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n",
    "                json.dump(comp, f, indent=2)\n",
    "                mlflow.log_artifact(f.name, \"analysis/model_comparison.json\"); tmp=f.name\n",
    "            os.remove(tmp)\n",
    "\n",
    "            # predictions\n",
    "            dfp = pd.DataFrame({\n",
    "                \"split\": [\"train\"]*len(y_train) + [\"test\"]*len(y_test),\n",
    "                \"actual\": np.concatenate([y_train.values, y_test.values]),\n",
    "                \"predicted\": np.concatenate([results[best][\"pred\"][\"train\"], results[best][\"pred\"][\"test\"]]),\n",
    "            })\n",
    "            dfp[\"residual\"] = dfp[\"actual\"] - dfp[\"predicted\"]\n",
    "            dfp[\"abs_residual\"] = np.abs(dfp[\"residual\"])\n",
    "            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".csv\", delete=False) as f:\n",
    "                dfp.to_csv(f.name, index=False)\n",
    "                mlflow.log_artifact(f.name, \"results/predictions_detailed.csv\"); tmp=f.name\n",
    "            os.remove(tmp)\n",
    "\n",
    "            # importance\n",
    "            try:\n",
    "                if hasattr(best_model,\"feature_importances_\"):\n",
    "                    imp = pd.DataFrame({\"feature\": X_train.columns, \"importance\": best_model.feature_importances_}) \\\n",
    "                          .sort_values(\"importance\", ascending=False)\n",
    "                    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".csv\", delete=False) as f:\n",
    "                        imp.to_csv(f.name, index=False)\n",
    "                        mlflow.log_artifact(f.name, \"analysis/feature_importance.csv\"); tmp=f.name\n",
    "                    os.remove(tmp)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # samples\n",
    "            tr = X_train.head(20).copy(); tr[\"target\"] = y_train.head(20).values; tr[\"split\"]=\"train\"\n",
    "            te = X_test.head(10).copy();  te[\"target\"] = y_test.head(10).values;  te[\"split\"]=\"test\"\n",
    "            samp = pd.concat([tr,te], ignore_index=True)\n",
    "            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".csv\", delete=False) as f:\n",
    "                samp.to_csv(f.name, index=False)\n",
    "                mlflow.log_artifact(f.name, \"data/training_samples.csv\"); tmp=f.name\n",
    "            os.remove(tmp)\n",
    "\n",
    "            # register or artifact-only\n",
    "            try:\n",
    "                sig = infer_signature(X_train, best_model.predict(X_train))\n",
    "                if self.registry_enabled:\n",
    "                    info = mlflow.sklearn.log_model(\n",
    "                        sk_model=best_model, name=\"best_model\",\n",
    "                        signature=sig, input_example=X_train.head(3),\n",
    "                        registered_model_name=\"covid_prediction_model\",\n",
    "                        serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE,\n",
    "                    )\n",
    "                    mlflow.log_text(info.model_uri, \"model_uri.txt\")\n",
    "                else:\n",
    "                    info = mlflow.sklearn.log_model(\n",
    "                        sk_model=best_model, name=\"best_model\",\n",
    "                        signature=sig, input_example=X_train.head(3),\n",
    "                    )\n",
    "                    mlflow.log_text(info.model_uri, \"model_uri_artifact_only.txt\")\n",
    "            except Exception as e2:\n",
    "                mlflow.log_text(f\"model_save_failed: {e2}\", \"model_save_failed.txt\")\n",
    "\n",
    "            # forecast\n",
    "            try:\n",
    "                df_fore = recursive_forecast_dynamic(df_feat, target, list(X_train.columns),\n",
    "                                                     best_model, self.cfg.horizon,\n",
    "                                                     self.cfg.lookbacks, self.cfg.rolls)\n",
    "                with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".csv\", delete=False) as f:\n",
    "                    df_fore.to_csv(f.name, index=False)\n",
    "                    mlflow.log_artifact(f.name, \"forecast/forecast_future.csv\"); tmp=f.name\n",
    "                os.remove(tmp)\n",
    "                _lineplot(df_fore[\"date\"], df_fore[\"yhat\"], f\"{best} forecast (future)\", f\"{best}_forecast.png\")\n",
    "            except Exception as e:\n",
    "                mlflow.log_text(str(e), \"forecast_error.txt\")\n",
    "\n",
    "            # summary\n",
    "            summ = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"total_models_trained\": len(results),\n",
    "                \"best_model\": best,\n",
    "                \"best_performance\": results[best][\"metrics\"][\"test\"],\n",
    "            }\n",
    "            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n",
    "                json.dump(summ, f, indent=2)\n",
    "                mlflow.log_artifact(f.name, \"reports/training_summary.json\"); tmp=f.name\n",
    "            os.remove(tmp)\n",
    "\n",
    "            return {\"best_model\": best, \"metrics\": results[best][\"metrics\"]}\n",
    "\n",
    "\n",
    "# ========================= CLI =========================\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--features_path\", type=str, required=True, help=\"CSV/TSV/Excel 파일 경로 또는 디렉터리\")\n",
    "    ap.add_argument(\"--target\", type=str, default=\"new_cases\")\n",
    "    ap.add_argument(\"--tracking_uri\", type=str, default=None, help=\"예: http://mlflow:8080 (없으면 자동 폴백)\")\n",
    "    ap.add_argument(\"--test_days\", type=int, default=60)\n",
    "    ap.add_argument(\"--horizon\", type=int, default=30)\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    # 0) 경로 자동 복구\n",
    "    table_path = resolve_table_path(args.features_path)\n",
    "    print(f\"[info] Using table file: {table_path}\")\n",
    "\n",
    "    # 1) 로드\n",
    "    df = read_table_robust(table_path)\n",
    "\n",
    "    # 2) date/target 확인 및 FE 보강\n",
    "    df = add_time_features(df, \"date\")\n",
    "    if args.target not in df.columns:\n",
    "        raise ValueError(f\"Target '{args.target}' not found. Columns: {list(df.columns)[:30]}\")\n",
    "    df = add_lag_roll(df, args.target, lags=(1,7,14), rolls=(7,14,28))\n",
    "\n",
    "    # 3) 학습\n",
    "    cfg = TrainConfig(target_col=args.target, test_days=args.test_days, horizon=args.horizon)\n",
    "    trainer = IntegratedCovidTrainer(cfg, tracking_uri=args.tracking_uri)\n",
    "    res = trainer.train(df, target=args.target)\n",
    "    print(\"DONE. Best:\", res[\"best_model\"], \"Test metrics:\", res[\"metrics\"][\"test\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
