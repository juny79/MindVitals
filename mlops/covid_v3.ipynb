{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335debc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "Exec  : /opt/conda/bin/python\n",
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas==2.2.2\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas==2.2.2)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas==2.2.2)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.2)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.2.2)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
      "\u001b[2K  Attempting uninstall: pytz\n",
      "\u001b[2K    Found existing installation: pytz 2025.2\n",
      "\u001b[2K    Uninstalling pytz-2025.2:\n",
      "\u001b[2K      Successfully uninstalled pytz-2025.2\n",
      "\u001b[2K  Attempting uninstall: tzdata\n",
      "\u001b[2K    Found existing installation: tzdata 2025.2\n",
      "\u001b[2K    Uninstalling tzdata-2025.2:\n",
      "\u001b[2K      Successfully uninstalled tzdata-2025.2\n",
      "\u001b[2K  Attempting uninstall: sixm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: six 1.17.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling six-1.17.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: numpy0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: python-dateutil[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0━━━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: pandas90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: pandas 2.2.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling pandas-2.2.2:━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m5/6\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.2.290m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m5/6\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [pandas]2m5/6\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-1.26.4 pandas-2.2.2 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 현재 커널/버전 확인(선택)\n",
    "import sys\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Exec  :\", sys.executable)\n",
    "\n",
    "# numpy/pandas 재설치 (호환 버전 고정)\n",
    "%pip install -U --force-reinstall \"numpy==1.26.4\" \"pandas==2.2.2\"\n",
    "\n",
    "# (선택) 추가로 자주 쓰는 것들\n",
    "%pip install -U scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374004da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "MLflow-친화 파이프라인 (v3, 개선판)\n",
    "- EDA -> Feature Engineering -> 여러 모델(Linear/RF/(XGB)) 학습/검증/미래예측\n",
    "- 변경점:\n",
    "  * mlflow 모델 로깅: artifact_path -> name (MLflow 3.x 경고 제거)\n",
    "  * 모델 로깅 가속: pip_requirements 최소화 또는 비활성화\n",
    "  * Permutation Importance 경량화: 테스트셋 샘플링(<=500), n_repeats=3\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import os, warnings, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ.setdefault(\"GIT_PYTHON_REFRESH\", \"quiet\")  # git 경고 숨김\n",
    "\n",
    "# ---------------- MLflow: 전역 임포트 (함수 내 재할당 금지) ----------------\n",
    "import mlflow\n",
    "import mlflow.data\n",
    "try:\n",
    "    import mlflow.sklearn as mlflow_sklearn\n",
    "except Exception:\n",
    "    mlflow_sklearn = None\n",
    "\n",
    "# autolog은 켜되, 느리면 꺼도 됩니다.\n",
    "try:\n",
    "    if mlflow_sklearn is not None:\n",
    "        mlflow_sklearn.autolog(log_models=False, log_input_examples=True, silent=True)\n",
    "        # log_models=False: 자동 모델 로깅은 끄고, 아래에서 수동으로 빠르게 로깅\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ---------------- 경로/설정 ----------------\n",
    "PROC = Path(\"/root/covid_processed.csv\")      # 입력(전처리 완료)\n",
    "FEAT = Path(\"/root/covid_features.csv\")       # FE 출력\n",
    "OUTDIR = Path(\"/root\")\n",
    "TARGET = \"new_cases\"                           # 필요시 변경\n",
    "HORIZON = 30                                   # 미래 예측일수\n",
    "TEST_DAYS = 60                                 # 테스트 구간(말일 기준)\n",
    "LOOKBACKS = [1, 7, 14]                         # 래그\n",
    "ROLLS = [7, 14, 28]                            # 롤링 윈도우\n",
    "EXPERIMENT_NAME = \"covid_timeseries_prophet_lstm\"  # 기존과 동일\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# ---------------- 로깅 도우미 ----------------\n",
    "def log_df_preview_md(df: pd.DataFrame, name: str, n: int = 20):\n",
    "    mlflow.log_text(df.head(n).to_markdown(index=False), f\"{name}_preview.md\")\n",
    "\n",
    "def log_json(d: dict, name: str):\n",
    "    mlflow.log_text(json.dumps(d, indent=2, ensure_ascii=False), f\"{name}.json\")\n",
    "\n",
    "def lineplot(dates, series, title, fname):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(dates, series)\n",
    "    plt.title(title); plt.xlabel(\"date\"); plt.ylabel(\"value\")\n",
    "    mlflow.log_figure(fig, fname)\n",
    "    plt.close(fig)\n",
    "\n",
    "def dualplot(dates, y_true, y_pred, title, fname):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(dates, y_true, label=\"actual\")\n",
    "    plt.plot(dates, y_pred, label=\"pred\")\n",
    "    plt.legend(); plt.title(title); plt.xlabel(\"date\"); plt.ylabel(\"value\")\n",
    "    mlflow.log_figure(fig, fname)\n",
    "    plt.close(fig)\n",
    "\n",
    "def residplot(y_true, y_pred, title, fname):\n",
    "    res = np.array(y_true) - np.array(y_pred)\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(y_pred, res, s=8)\n",
    "    plt.axhline(0, color=\"gray\"); plt.title(title)\n",
    "    plt.xlabel(\"pred\"); plt.ylabel(\"residuals\")\n",
    "    mlflow.log_figure(fig, fname)\n",
    "    plt.close(fig)\n",
    "\n",
    "def corr_heatmap(df: pd.DataFrame, fname=\"eda_corr_heatmap.png\", max_cols=30):\n",
    "    try:\n",
    "        import seaborn as sns  # 선택\n",
    "        cols = df.select_dtypes(include=[np.number]).columns.tolist()[:max_cols]\n",
    "        if len(cols) >= 2:\n",
    "            fig = plt.figure(figsize=(6,5))\n",
    "            sns.heatmap(df[cols].corr(), cmap=\"coolwarm\", center=0)\n",
    "            plt.title(\"Correlation (numeric, head)\")\n",
    "            mlflow.log_figure(fig, fname); plt.close(fig)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ---------------- 피처 엔지니어링 ----------------\n",
    "def add_time_features(df: pd.DataFrame, date_col=\"date\"):\n",
    "    if date_col not in df.columns: \n",
    "        return df\n",
    "    df[\"date\"] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    df[\"dow\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"weekofyear\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "    df[\"dayofyear\"] = df[\"date\"].dt.dayofyear\n",
    "    df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dow\"]/7); df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dow\"]/7)\n",
    "    if \"month\" in df.columns:\n",
    "        df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12); df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "    return df\n",
    "\n",
    "def add_lag_roll(df: pd.DataFrame, target: str, lags, rolls):\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    for l in lags:\n",
    "        df[f\"{target}_lag{l}\"] = df[target].shift(l)\n",
    "    for w in rolls:\n",
    "        df[f\"{target}_rollmean{w}\"] = df[target].shift(1).rolling(w, min_periods=1).mean()\n",
    "        df[f\"{target}_rollstd{w}\"]  = df[target].shift(1).rolling(w, min_periods=1).std()\n",
    "    df[f\"{target}_diff1\"] = df[target].diff(1)\n",
    "    df[f\"{target}_pct\"]   = df[target].pct_change().replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.bfill().ffill()\n",
    "    return df\n",
    "\n",
    "def feature_engineer(in_path: Path, target: str, out_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(in_path)\n",
    "    if \"date\" not in df.columns: \n",
    "        raise ValueError(\"Need 'date' column.\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df = add_time_features(df)\n",
    "    df = add_lag_roll(df, target, LOOKBACKS, ROLLS)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[num_cols] = df[num_cols].interpolate(\"linear\", limit_direction=\"both\")\n",
    "    df = df.bfill().ffill()\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_path, index=False)\n",
    "    return df\n",
    "\n",
    "# ---------------- 데이터셋/스플릿 ----------------\n",
    "def time_split(df: pd.DataFrame, test_days: int):\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    cutoff = df[\"date\"].max() - pd.Timedelta(days=test_days-1)\n",
    "    train = df[df[\"date\"] < cutoff].copy()\n",
    "    test  = df[df[\"date\"] >= cutoff].copy()\n",
    "    return train, test\n",
    "\n",
    "def build_xy(df: pd.DataFrame, target: str):\n",
    "    df = df.sort_values(\"date\")\n",
    "    df[\"y_next\"] = df[target].shift(-1)  # 1-step ahead\n",
    "    feats = [c for c in df.select_dtypes(include=[np.number]).columns if c not in [target,\"y_next\"]]\n",
    "    df = df.dropna(subset=[\"y_next\"])\n",
    "    X = df[feats].values.astype(np.float32)\n",
    "    y = df[\"y_next\"].values.astype(np.float32)\n",
    "    idx = df.index  # 라벨 인덱스\n",
    "    return X, y, feats, idx\n",
    "\n",
    "# ---------------- 평가 ----------------\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "def reg_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = float(np.mean(np.abs((y_true - y_pred)/np.maximum(1e-9, np.abs(y_true))))*100.0)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"MAE\": float(mae), \"RMSE\": float(rmse), \"MAPE\": float(mape), \"R2\": float(r2)}\n",
    "\n",
    "# ---------------- 재귀 예측(미래 H일) ----------------\n",
    "def recursive_forecast(df_feat: pd.DataFrame, feats: list, model, horizon: int, target: str) -> pd.DataFrame:\n",
    "    df = df_feat.sort_values(\"date\").copy()\n",
    "    out_dates = pd.date_range(df[\"date\"].max() + pd.Timedelta(days=1), periods=horizon, freq=\"D\")\n",
    "    preds = []\n",
    "    x_last = df[feats].iloc[-1].values.reshape(1, -1)  # 간단: 고정 입력\n",
    "    for _ in range(horizon):\n",
    "        yhat = float(model.predict(x_last)[0])\n",
    "        preds.append(yhat)\n",
    "    return pd.DataFrame({\"date\": out_dates, \"yhat\": preds})\n",
    "\n",
    "# ---------------- Permutation Importance (경량화) ----------------\n",
    "def permutation_importance_light(model, X, y, feats, n_repeats=3, max_rows=500):\n",
    "    try:\n",
    "        from sklearn.inspection import permutation_importance as sk_perm\n",
    "        if len(X) > max_rows:\n",
    "            # 무작위 샘플링으로 비용 절감\n",
    "            idx = np.random.RandomState(42).choice(len(X), size=max_rows, replace=False)\n",
    "            Xs, ys = X[idx], y[idx]\n",
    "        else:\n",
    "            Xs, ys = X, y\n",
    "        r = sk_perm(model, Xs, ys, n_repeats=n_repeats, random_state=42, n_jobs=-1)\n",
    "        imp = pd.DataFrame({\"feature\": feats, \"importance\": r.importances_mean}).sort_values(\"importance\", ascending=False)\n",
    "        return imp\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------------- 안전한 모델 로깅 (MLflow 3.x 호환) ----------------\n",
    "def safe_log_sklearn_model(model, name: str, signature=None, input_example=None, pip_reqs_min=True):\n",
    "    \"\"\"\n",
    "    MLflow 3.x: name= 권장. 오래 걸리는 환경 스냅샷을 피하려 pip_requirements 최소화/생략.\n",
    "    \"\"\"\n",
    "    if mlflow_sklearn is None:\n",
    "        return\n",
    "    kwargs = {}\n",
    "    if signature is not None: kwargs[\"signature\"] = signature\n",
    "    if input_example is not None: kwargs[\"input_example\"] = input_example\n",
    "    if pip_reqs_min:\n",
    "        # 최소 요구사항만 기록하거나, 아예 비활성화도 가능\n",
    "        kwargs[\"pip_requirements\"] = [\"mlflow\", \"scikit-learn\"]\n",
    "    try:\n",
    "        mlflow_sklearn.log_model(sk_model=model, name=name, **kwargs)\n",
    "    except TypeError:\n",
    "        # 구버전 호환(경고는 감수)\n",
    "        mlflow_sklearn.log_model(model, artifact_path=name, **kwargs)\n",
    "\n",
    "def safe_log_xgb_model(model, name: str, signature=None, input_example=None, pip_reqs_min=True):\n",
    "    try:\n",
    "        import mlflow.xgboost as mlflow_xgb\n",
    "    except Exception:\n",
    "        return\n",
    "    kwargs = {}\n",
    "    if signature is not None: kwargs[\"signature\"] = signature\n",
    "    if input_example is not None: kwargs[\"input_example\"] = input_example\n",
    "    if pip_reqs_min:\n",
    "        kwargs[\"pip_requirements\"] = [\"mlflow\", \"xgboost\"]\n",
    "    try:\n",
    "        mlflow_xgb.log_model(model, name=name, **kwargs)\n",
    "    except TypeError:\n",
    "        mlflow_xgb.log_model(model, artifact_path=name, **kwargs)\n",
    "\n",
    "# ==================== main ====================\n",
    "def main():\n",
    "    assert PROC.exists(), f\"Processed CSV not found: {PROC}\"\n",
    "    base_df = pd.read_csv(PROC)\n",
    "    if \"date\" not in base_df.columns or TARGET not in base_df.columns:\n",
    "        raise ValueError(\"Input must have 'date' and target.\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"experiment_run\") as parent_run:\n",
    "\n",
    "        # ----- 0) EDA -----\n",
    "        with mlflow.start_run(run_name=\"data_and_eda\", nested=True):\n",
    "            ds = mlflow.data.from_pandas(base_df, source=str(PROC), name=\"raw_processed\")\n",
    "            mlflow.log_input(ds, context=\"training\")\n",
    "            mlflow.log_metrics({\n",
    "                \"rows\": len(base_df),\n",
    "                \"cols\": base_df.shape[1],\n",
    "                \"missing_total\": int(base_df.isnull().sum().sum())\n",
    "            })\n",
    "            try:\n",
    "                dfp = base_df.copy()\n",
    "                dfp[\"date\"] = pd.to_datetime(dfp[\"date\"], errors=\"coerce\")\n",
    "                dfp = dfp.dropna(subset=[\"date\"]).sort_values(\"date\")\n",
    "                lineplot(dfp[\"date\"], dfp[TARGET], f\"{TARGET} over time\", \"eda_target.png\")\n",
    "                corr_heatmap(dfp, \"eda_corr_heatmap.png\", max_cols=30)\n",
    "            except Exception:\n",
    "                pass\n",
    "            log_df_preview_md(base_df, \"raw_preview\", 20)\n",
    "\n",
    "        # ----- 1) Feature Engineering -----\n",
    "        with mlflow.start_run(run_name=\"feature_engineering\", nested=True):\n",
    "            df_feat = feature_engineer(PROC, TARGET, FEAT)\n",
    "            ds = mlflow.data.from_pandas(df_feat, source=str(FEAT), name=\"feature_engineered\")\n",
    "            mlflow.log_input(ds, context=\"training\")\n",
    "            mlflow.log_metrics({\"fe_rows\": len(df_feat), \"fe_cols\": df_feat.shape[1]})\n",
    "            mlflow.log_artifact(str(FEAT))\n",
    "            log_df_preview_md(df_feat, \"fe_preview\", 20)\n",
    "\n",
    "        # ----- 2) 모델 학습/검증/미래예측 -----\n",
    "        df_feat = pd.read_csv(FEAT)\n",
    "        df_feat[\"date\"] = pd.to_datetime(df_feat[\"date\"], errors=\"coerce\")\n",
    "        train_df, test_df = time_split(df_feat, TEST_DAYS)\n",
    "\n",
    "        # datasets lineage\n",
    "        train_ds = mlflow.data.from_pandas(train_df, name=\"train_dataset\")\n",
    "        test_ds  = mlflow.data.from_pandas(test_df,  name=\"test_dataset\")\n",
    "\n",
    "        # 공통 X,y\n",
    "        X_train, y_train, feats, idx_train = build_xy(train_df, TARGET)\n",
    "        X_test,  y_test,  _,    idx_test  = build_xy(test_df,  TARGET)\n",
    "\n",
    "        # ---- 모델 1: Linear Regression\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        with mlflow.start_run(run_name=\"model_linear\", nested=True):\n",
    "            mlflow.log_params({\"algo\":\"LinearRegression\",\"horizon\":HORIZON,\"test_days\":TEST_DAYS,\n",
    "                               \"lookbacks\":\",\".join(map(str,LOOKBACKS)),\"rolls\":\",\".join(map(str,ROLLS))})\n",
    "            mlflow.log_input(train_ds, context=\"training\")\n",
    "            mlflow.log_input(test_ds,  context=\"testing\")\n",
    "\n",
    "            mdl = LinearRegression()\n",
    "            mdl.fit(X_train, y_train)\n",
    "            pred_test = mdl.predict(X_test)\n",
    "\n",
    "            m = reg_metrics(y_test, pred_test)\n",
    "            mlflow.log_metrics({f\"test_{k}\":v for k,v in m.items()})\n",
    "\n",
    "            dt_test = test_df.loc[idx_test, \"date\"]   # 라벨 인덱스는 loc로\n",
    "            dualplot(dt_test, y_test, pred_test, \"Linear: actual vs pred (test)\", \"lin_test_pred.png\")\n",
    "            residplot(y_test, pred_test, \"Linear: residuals (test)\", \"lin_test_resid.png\")\n",
    "\n",
    "            imp = permutation_importance_light(mdl, X_test, y_test, feats, n_repeats=3, max_rows=500)\n",
    "            if imp is not None:\n",
    "                mlflow.log_text(imp.head(30).to_markdown(index=False), \"lin_perm_importance.md\")\n",
    "\n",
    "            df_fore = recursive_forecast(df_feat, feats, mdl, HORIZON, TARGET)\n",
    "            fore_path = OUTDIR / \"linear_forecast.csv\"\n",
    "            df_fore.to_csv(fore_path, index=False)\n",
    "            mlflow.log_artifact(str(fore_path))\n",
    "            lineplot(df_fore[\"date\"], df_fore[\"yhat\"], \"Linear forecast (future)\", \"lin_forecast.png\")\n",
    "\n",
    "            try:\n",
    "                sig = mlflow.models.infer_signature(X_train[:5], mdl.predict(X_train[:5]))\n",
    "                safe_log_sklearn_model(mdl, name=\"model_linear\", signature=sig, input_example=X_train[:5], pip_reqs_min=True)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # ---- 모델 2: RandomForest\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        with mlflow.start_run(run_name=\"model_rf\", nested=True):\n",
    "            params = {\"algo\":\"RandomForestRegressor\",\"n_estimators\":400,\"max_depth\":12,\"min_samples_leaf\":2,\n",
    "                      \"n_jobs\":-1,\"random_state\":42,\"horizon\":HORIZON,\"test_days\":TEST_DAYS}\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_input(train_ds, context=\"training\"); mlflow.log_input(test_ds, context=\"testing\")\n",
    "\n",
    "            rf = RandomForestRegressor(\n",
    "                n_estimators=params[\"n_estimators\"],\n",
    "                max_depth=params[\"max_depth\"],\n",
    "                min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "                n_jobs=-1, random_state=42\n",
    "            )\n",
    "            rf.fit(X_train, y_train)\n",
    "            pred_test = rf.predict(X_test)\n",
    "\n",
    "            m = reg_metrics(y_test, pred_test)\n",
    "            mlflow.log_metrics({f\"test_{k}\":v for k,v in m.items()})\n",
    "\n",
    "            dt_test = test_df.loc[idx_test, \"date\"]\n",
    "            dualplot(dt_test, y_test, pred_test, \"RF: actual vs pred (test)\", \"rf_test_pred.png\")\n",
    "            residplot(y_test, pred_test, \"RF: residuals (test)\", \"rf_test_resid.png\")\n",
    "\n",
    "            imp = permutation_importance_light(rf, X_test, y_test, feats, n_repeats=3, max_rows=500)\n",
    "            if imp is not None:\n",
    "                mlflow.log_text(imp.head(30).to_markdown(index=False), \"rf_perm_importance.md\")\n",
    "\n",
    "            df_fore = recursive_forecast(df_feat, feats, rf, HORIZON, TARGET)\n",
    "            fore_path = OUTDIR / \"rf_forecast.csv\"\n",
    "            df_fore.to_csv(fore_path, index=False)\n",
    "            mlflow.log_artifact(str(fore_path))\n",
    "            lineplot(df_fore[\"date\"], df_fore[\"yhat\"], \"RF forecast (future)\", \"rf_forecast.png\")\n",
    "\n",
    "            try:\n",
    "                sig = mlflow.models.infer_signature(X_train[:5], rf.predict(X_train[:5]))\n",
    "                safe_log_sklearn_model(rf, name=\"model_rf\", signature=sig, input_example=X_train[:5], pip_reqs_min=True)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # ---- (선택) 모델 3: XGBoost (설치 시 자동)\n",
    "        try:\n",
    "            from xgboost import XGBRegressor\n",
    "            with mlflow.start_run(run_name=\"model_xgb\", nested=True):\n",
    "                params = {\"algo\":\"XGBRegressor\",\"n_estimators\":600,\"max_depth\":6,\"learning_rate\":0.05,\n",
    "                          \"subsample\":0.9,\"colsample_bytree\":0.9,\"random_state\":42,\n",
    "                          \"reg_lambda\":1.0,\"horizon\":HORIZON,\"test_days\":TEST_DAYS}\n",
    "                mlflow.log_params(params); mlflow.log_input(train_ds, \"training\"); mlflow.log_input(test_ds, \"testing\")\n",
    "\n",
    "                xgb = XGBRegressor(\n",
    "                    n_estimators=params[\"n_estimators\"], max_depth=params[\"max_depth\"],\n",
    "                    learning_rate=params[\"learning_rate\"], subsample=params[\"subsample\"],\n",
    "                    colsample_bytree=params[\"colsample_bytree\"], random_state=42, n_jobs=-1,\n",
    "                    reg_lambda=params[\"reg_lambda\"], tree_method=\"hist\"\n",
    "                )\n",
    "                xgb.fit(X_train, y_train)\n",
    "                pred_test = xgb.predict(X_test)\n",
    "\n",
    "                m = reg_metrics(y_test, pred_test)\n",
    "                mlflow.log_metrics({f\"test_{k}\":v for k,v in m.items()})\n",
    "\n",
    "                dt_test = test_df.loc[idx_test, \"date\"]\n",
    "                dualplot(dt_test, y_test, pred_test, \"XGB: actual vs pred (test)\", \"xgb_test_pred.png\")\n",
    "                residplot(y_test, pred_test, \"XGB: residuals (test)\", \"xgb_test_resid.png\")\n",
    "\n",
    "                df_fore = recursive_forecast(df_feat, feats, xgb, HORIZON, TARGET)\n",
    "                fore_path = OUTDIR / \"xgb_forecast.csv\"\n",
    "                df_fore.to_csv(fore_path, index=False)\n",
    "                mlflow.log_artifact(str(fore_path))\n",
    "                lineplot(df_fore[\"date\"], df_fore[\"yhat\"], \"XGB forecast (future)\", \"xgb_forecast.png\")\n",
    "\n",
    "                try:\n",
    "                    sig = mlflow.models.infer_signature(X_train[:5], xgb.predict(X_train[:5]))\n",
    "                    safe_log_xgb_model(xgb, name=\"model_xgb\", signature=sig, input_example=X_train[:5], pip_reqs_min=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass  # xgboost 미설치면 자동 스킵\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
