{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec3fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "MLflow-친화 파이프라인 (v4, 더 개선판)\n",
    "- 문제점 수정:\n",
    "  1) 미래 피처 생성 가능한 컬럼만 사용 (화이트리스트)\n",
    "  2) 재귀 예측 시, 예측값으로 래그/롤링/증감/pct를 동적으로 갱신\n",
    "- 구성: EDA -> FE -> 모델들(Linear/RF/(XGB)) 학습/검증/미래예측\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import os, warnings, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ.setdefault(\"GIT_PYTHON_REFRESH\", \"quiet\")\n",
    "\n",
    "# ---------------- MLflow 전역 임포트 ----------------\n",
    "import mlflow\n",
    "import mlflow.data\n",
    "try:\n",
    "    import mlflow.sklearn as mlflow_sklearn\n",
    "except Exception:\n",
    "    mlflow_sklearn = None\n",
    "\n",
    "# autolog는 입력예시만 남기고 모델은 수동 로깅(속도 개선)\n",
    "try:\n",
    "    if mlflow_sklearn is not None:\n",
    "        mlflow_sklearn.autolog(log_models=False, log_input_examples=True, silent=True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ---------------- 경로/설정 ----------------\n",
    "PROC = Path(\"/root/covid_processed.csv\")\n",
    "FEAT = Path(\"/root/covid_features.csv\")\n",
    "OUTDIR = Path(\"/root\")\n",
    "TARGET = \"new_cases\"            # 필요시 변경\n",
    "HORIZON = 30                    # 미래 예측일 수\n",
    "TEST_DAYS = 60                  # 고정 테스트 구간(최근 60일)\n",
    "LOOKBACKS = [1, 7, 14]          # 래그\n",
    "ROLLS = [7, 14, 28]             # 롤링\n",
    "EXPERIMENT_NAME = \"covid_timeseries_prophet_lstm\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# ---------------- 로깅 유틸 ----------------\n",
    "def log_df_preview_md(df: pd.DataFrame, name: str, n: int = 20):\n",
    "    mlflow.log_text(df.head(n).to_markdown(index=False), f\"{name}_preview.md\")\n",
    "\n",
    "def lineplot(dates, series, title, fname):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(dates, series)\n",
    "    plt.title(title); plt.xlabel(\"date\"); plt.ylabel(\"value\")\n",
    "    mlflow.log_figure(fig, fname); plt.close(fig)\n",
    "\n",
    "def dualplot(dates, y_true, y_pred, title, fname):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(dates, y_true, label=\"actual\")\n",
    "    plt.plot(dates, y_pred, label=\"pred\")\n",
    "    plt.legend(); plt.title(title); plt.xlabel(\"date\"); plt.ylabel(\"value\")\n",
    "    mlflow.log_figure(fig, fname); plt.close(fig)\n",
    "\n",
    "def residplot(y_true, y_pred, title, fname):\n",
    "    res = np.array(y_true) - np.array(y_pred)\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(y_pred, res, s=8)\n",
    "    plt.axhline(0, color=\"gray\"); plt.title(title)\n",
    "    plt.xlabel(\"pred\"); plt.ylabel(\"residuals\")\n",
    "    mlflow.log_figure(fig, fname); plt.close(fig)\n",
    "\n",
    "def corr_heatmap(df: pd.DataFrame, fname=\"eda_corr_heatmap.png\", max_cols=30):\n",
    "    try:\n",
    "        import seaborn as sns\n",
    "        cols = df.select_dtypes(include=[np.number]).columns.tolist()[:max_cols]\n",
    "        if len(cols) >= 2:\n",
    "            fig = plt.figure(figsize=(6,5))\n",
    "            sns.heatmap(df[cols].corr(), cmap=\"coolwarm\", center=0)\n",
    "            plt.title(\"Correlation (numeric, head)\")\n",
    "            mlflow.log_figure(fig, fname); plt.close(fig)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ---------------- FE ----------------\n",
    "def add_time_features(df: pd.DataFrame, date_col=\"date\"):\n",
    "    if date_col not in df.columns: \n",
    "        return df\n",
    "    df[\"date\"] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    df[\"dow\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"weekofyear\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "    df[\"dayofyear\"] = df[\"date\"].dt.dayofyear\n",
    "    df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dow\"]/7); df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dow\"]/7)\n",
    "    if \"month\" in df.columns:\n",
    "        df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12); df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "    return df\n",
    "\n",
    "def add_lag_roll(df: pd.DataFrame, target: str, lags, rolls):\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    for l in lags:\n",
    "        df[f\"{target}_lag{l}\"] = df[target].shift(l)\n",
    "    for w in rolls:\n",
    "        df[f\"{target}_rollmean{w}\"] = df[target].shift(1).rolling(w, min_periods=1).mean()\n",
    "        df[f\"{target}_rollstd{w}\"]  = df[target].shift(1).rolling(w, min_periods=1).std()\n",
    "    df[f\"{target}_diff1\"] = df[target].diff(1)\n",
    "    df[f\"{target}_pct\"]   = df[target].pct_change().replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.bfill().ffill()\n",
    "    return df\n",
    "\n",
    "def feature_engineer(in_path: Path, target: str, out_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(in_path)\n",
    "    if \"date\" not in df.columns: \n",
    "        raise ValueError(\"Need 'date' column.\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df = add_time_features(df)\n",
    "    df = add_lag_roll(df, target, LOOKBACKS, ROLLS)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[num_cols] = df[num_cols].interpolate(\"linear\", limit_direction=\"both\")\n",
    "    df = df.bfill().ffill()\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_path, index=False)\n",
    "    return df\n",
    "\n",
    "# ---------------- 피처 선택(화이트리스트) ----------------\n",
    "DATE_FEATS = [\"dow_sin\",\"dow_cos\",\"weekofyear\",\"dayofyear\",\"month_sin\",\"month_cos\"]\n",
    "\n",
    "def select_future_aware_features(df: pd.DataFrame, target: str) -> list:\n",
    "    \"\"\"\n",
    "    미래 시점에도 스스로 생성 가능한 피처만 사용:\n",
    "    - TARGET의 lag/rolling/diff/pct\n",
    "    - 날짜 기반 주기 피처 (DATE_FEATS)\n",
    "    \"\"\"\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    allowed = []\n",
    "    for c in num_cols:\n",
    "        if c in DATE_FEATS:\n",
    "            allowed.append(c)\n",
    "        elif c.startswith(f\"{target}_\"):\n",
    "            allowed.append(c)\n",
    "    # 타깃과 y_next는 제외\n",
    "    allowed = [c for c in allowed if c != target and c != \"y_next\"]\n",
    "    # 존재하는 컬럼만\n",
    "    allowed = [c for c in allowed if c in df.columns]\n",
    "    return sorted(list(dict.fromkeys(allowed)))\n",
    "\n",
    "# ---------------- 데이터셋/스플릿 ----------------\n",
    "def time_split(df: pd.DataFrame, test_days: int):\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    cutoff = df[\"date\"].max() - pd.Timedelta(days=test_days-1)\n",
    "    train = df[df[\"date\"] < cutoff].copy()\n",
    "    test  = df[df[\"date\"] >= cutoff].copy()\n",
    "    return train, test\n",
    "\n",
    "def build_xy(df: pd.DataFrame, target: str, feat_list: list):\n",
    "    df = df.sort_values(\"date\")\n",
    "    df[\"y_next\"] = df[target].shift(-1)  # 1-step ahead\n",
    "    df = df.dropna(subset=[\"y_next\"])\n",
    "    X = df[feat_list].values.astype(np.float32)\n",
    "    y = df[\"y_next\"].values.astype(np.float32)\n",
    "    idx = df.index  # 라벨 인덱스\n",
    "    return X, y, idx\n",
    "\n",
    "# ---------------- 평가 ----------------\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "def reg_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = float(np.mean(np.abs((y_true - y_pred)/np.maximum(1e-9, np.abs(y_true))))*100.0)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"MAE\": float(mae), \"RMSE\": float(rmse), \"MAPE\": float(mape), \"R2\": float(r2)}\n",
    "\n",
    "# ---------------- 동적 재귀 예측 ----------------\n",
    "def _roll_stats(seq, w):\n",
    "    arr = np.array(seq[-w:], dtype=float)\n",
    "    return float(np.mean(arr)), float(np.std(arr, ddof=0))\n",
    "\n",
    "def _date_feats(next_date):\n",
    "    dow = next_date.dayofweek\n",
    "    weekofyear = int(next_date.isocalendar().week)\n",
    "    dayofyear  = int(next_date.timetuple().tm_yday)\n",
    "    month = int(next_date.month)\n",
    "    out = {\n",
    "        \"dow_sin\": np.sin(2*np.pi*dow/7.0),\n",
    "        \"dow_cos\": np.cos(2*np.pi*dow/7.0),\n",
    "        \"weekofyear\": weekofyear,\n",
    "        \"dayofyear\": dayofyear,\n",
    "        \"month_sin\": np.sin(2*np.pi*month/12.0),\n",
    "        \"month_cos\": np.cos(2*np.pi*month/12.0),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def recursive_forecast_dynamic(df_feat: pd.DataFrame, target: str, feat_list: list, model, horizon: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    마지막 관측까지의 target 히스토리로부터 미래 H일을 동적으로 생성.\n",
    "    - 매 스텝 예측값을 래그/롤링/증감/pct 계산에 주입\n",
    "    - 날짜 주기 피처는 next_date로 갱신\n",
    "    \"\"\"\n",
    "    df = df_feat.sort_values(\"date\").copy()\n",
    "    last_date = df[\"date\"].max()\n",
    "    # 타깃 히스토리\n",
    "    hist = df[target].tolist()\n",
    "    preds, dates = [], []\n",
    "\n",
    "    max_lag = max(LOOKBACKS) if LOOKBACKS else 1\n",
    "\n",
    "    for i in range(1, horizon+1):\n",
    "        nd = last_date + pd.Timedelta(days=i)\n",
    "        # 필요한 피처 벡터 구성\n",
    "        feat_row = {}\n",
    "\n",
    "        # 날짜 피처\n",
    "        feat_row.update(_date_feats(nd))\n",
    "\n",
    "        # 래그들\n",
    "        for l in LOOKBACKS:\n",
    "            feat_row[f\"{target}_lag{l}\"] = float(hist[-l]) if len(hist) >= l else float(hist[-1])\n",
    "\n",
    "        # 롤링 통계\n",
    "        for w in ROLLS:\n",
    "            m, s = _roll_stats(hist, min(len(hist), w))\n",
    "            feat_row[f\"{target}_rollmean{w}\"] = m\n",
    "            feat_row[f\"{target}_rollstd{w}\"] = s\n",
    "\n",
    "        # 증감/비율\n",
    "        if len(hist) >= 2:\n",
    "            diff1 = hist[-1] - hist[-2]\n",
    "            pct   = (hist[-1] - (hist[-2] if hist[-2] != 0 else 1e-9)) / max(abs(hist[-2]), 1e-9)\n",
    "        else:\n",
    "            diff1, pct = 0.0, 0.0\n",
    "        feat_row[f\"{target}_diff1\"] = float(diff1)\n",
    "        feat_row[f\"{target}_pct\"]   = float(pct)\n",
    "\n",
    "        # 모델이 실제로 쓰는 컬럼 순서에 맞춰 배열화\n",
    "        x = np.array([[feat_row.get(c, 0.0) for c in feat_list]], dtype=np.float32)\n",
    "        yhat = float(model.predict(x)[0])\n",
    "\n",
    "        # 누적\n",
    "        preds.append(yhat)\n",
    "        dates.append(nd)\n",
    "        hist.append(yhat)  # 예측값을 히스토리에 추가(다음 스텝에 사용)\n",
    "\n",
    "    return pd.DataFrame({\"date\": dates, \"yhat\": preds})\n",
    "\n",
    "# ---------------- Permutation Importance (경량화) ----------------\n",
    "def permutation_importance_light(model, X, y, feats, n_repeats=3, max_rows=500):\n",
    "    try:\n",
    "        from sklearn.inspection import permutation_importance as sk_perm\n",
    "        if len(X) > max_rows:\n",
    "            idx = np.random.RandomState(42).choice(len(X), size=max_rows, replace=False)\n",
    "            Xs, ys = X[idx], y[idx]\n",
    "        else:\n",
    "            Xs, ys = X, y\n",
    "        r = sk_perm(model, Xs, ys, n_repeats=n_repeats, random_state=42, n_jobs=-1)\n",
    "        imp = pd.DataFrame({\"feature\": feats, \"importance\": r.importances_mean}).sort_values(\"importance\", ascending=False)\n",
    "        return imp\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------------- 안전한 모델 로깅 ----------------\n",
    "def safe_log_sklearn_model(model, name: str, signature=None, input_example=None, pip_reqs_min=True):\n",
    "    if mlflow_sklearn is None:\n",
    "        return\n",
    "    kwargs = {}\n",
    "    if signature is not None: kwargs[\"signature\"] = signature\n",
    "    if input_example is not None: kwargs[\"input_example\"] = input_example\n",
    "    if pip_reqs_min:\n",
    "        kwargs[\"pip_requirements\"] = [\"mlflow\", \"scikit-learn\"]\n",
    "    try:\n",
    "        mlflow_sklearn.log_model(sk_model=model, name=name, **kwargs)\n",
    "    except TypeError:\n",
    "        mlflow_sklearn.log_model(model, artifact_path=name, **kwargs)\n",
    "\n",
    "def safe_log_xgb_model(model, name: str, signature=None, input_example=None, pip_reqs_min=True):\n",
    "    try:\n",
    "        import mlflow.xgboost as mlflow_xgb\n",
    "    except Exception:\n",
    "        return\n",
    "    kwargs = {}\n",
    "    if signature is not None: kwargs[\"signature\"] = signature\n",
    "    if input_example is not None: kwargs[\"input_example\"] = input_example\n",
    "    if pip_reqs_min:\n",
    "        kwargs[\"pip_requirements\"] = [\"mlflow\", \"xgboost\"]\n",
    "    try:\n",
    "        mlflow_xgb.log_model(model, name=name, **kwargs)\n",
    "    except TypeError:\n",
    "        mlflow_xgb.log_model(model, artifact_path=name, **kwargs)\n",
    "\n",
    "# ==================== main ====================\n",
    "def main():\n",
    "    assert PROC.exists(), f\"Processed CSV not found: {PROC}\"\n",
    "    base_df = pd.read_csv(PROC)\n",
    "    if \"date\" not in base_df.columns or TARGET not in base_df.columns:\n",
    "        raise ValueError(\"Input must have 'date' and target.\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"experiment_run\"):\n",
    "\n",
    "        # ----- 0) EDA -----\n",
    "        with mlflow.start_run(run_name=\"data_and_eda\", nested=True):\n",
    "            ds = mlflow.data.from_pandas(base_df, source=str(PROC), name=\"raw_processed\")\n",
    "            mlflow.log_input(ds, context=\"training\")\n",
    "            mlflow.log_metrics({\n",
    "                \"rows\": len(base_df),\n",
    "                \"cols\": base_df.shape[1],\n",
    "                \"missing_total\": int(base_df.isnull().sum().sum())\n",
    "            })\n",
    "            try:\n",
    "                dfp = base_df.copy()\n",
    "                dfp[\"date\"] = pd.to_datetime(dfp[\"date\"], errors=\"coerce\")\n",
    "                dfp = dfp.dropna(subset=[\"date\"]).sort_values(\"date\")\n",
    "                lineplot(dfp[\"date\"], dfp[TARGET], f\"{TARGET} over time\", \"eda_target.png\")\n",
    "                corr_heatmap(dfp, \"eda_corr_heatmap.png\", max_cols=30)\n",
    "            except Exception:\n",
    "                pass\n",
    "            log_df_preview_md(base_df, \"raw_preview\", 20)\n",
    "\n",
    "        # ----- 1) Feature Engineering -----\n",
    "        with mlflow.start_run(run_name=\"feature_engineering\", nested=True):\n",
    "            df_feat = feature_engineer(PROC, TARGET, FEAT)\n",
    "            ds = mlflow.data.from_pandas(df_feat, source=str(FEAT), name=\"feature_engineered\")\n",
    "            mlflow.log_input(ds, context=\"training\")\n",
    "            mlflow.log_metrics({\"fe_rows\": len(df_feat), \"fe_cols\": df_feat.shape[1]})\n",
    "            mlflow.log_artifact(str(FEAT))\n",
    "            log_df_preview_md(df_feat, \"fe_preview\", 20)\n",
    "\n",
    "        # ----- 2) 모델 학습/검증/미래예측 -----\n",
    "        df_feat = pd.read_csv(FEAT)\n",
    "        df_feat[\"date\"] = pd.to_datetime(df_feat[\"date\"], errors=\"coerce\")\n",
    "        # 미래 가능 피처만 선택\n",
    "        feat_list = select_future_aware_features(df_feat, TARGET)\n",
    "        with mlflow.start_run(run_name=\"features_used\", nested=True):\n",
    "            mlflow.log_text(\"\\n\".join(feat_list), \"features_used.txt\")\n",
    "\n",
    "        train_df, test_df = time_split(df_feat, TEST_DAYS)\n",
    "        train_ds = mlflow.data.from_pandas(train_df, name=\"train_dataset\")\n",
    "        test_ds  = mlflow.data.from_pandas(test_df,  name=\"test_dataset\")\n",
    "\n",
    "        # 공통 X,y\n",
    "        X_train, y_train, idx_train = build_xy(train_df, TARGET, feat_list)\n",
    "        X_test,  y_test,  idx_test  = build_xy(test_df,  TARGET, feat_list)\n",
    "\n",
    "        # ---- 모델 1: Linear Regression\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        with mlflow.start_run(run_name=\"model_linear\", nested=True):\n",
    "            mlflow.log_params({\"algo\":\"LinearRegression\",\"horizon\":HORIZON,\"test_days\":TEST_DAYS,\n",
    "                               \"lookbacks\":\",\".join(map(str,LOOKBACKS)),\"rolls\":\",\".join(map(str,ROLLS)),\n",
    "                               \"feat_count\":len(feat_list)})\n",
    "            mlflow.log_input(train_ds, context=\"training\")\n",
    "            mlflow.log_input(test_ds,  context=\"testing\")\n",
    "\n",
    "            mdl = LinearRegression()\n",
    "            mdl.fit(X_train, y_train)\n",
    "            pred_test = mdl.predict(X_test)\n",
    "            m = reg_metrics(y_test, pred_test)\n",
    "            mlflow.log_metrics({f\"test_{k}\":v for k,v in m.items()})\n",
    "\n",
    "            dt_test = test_df.loc[idx_test, \"date\"]\n",
    "            dualplot(dt_test, y_test, pred_test, \"Linear: actual vs pred (test)\", \"lin_test_pred.png\")\n",
    "            residplot(y_test, pred_test, \"Linear: residuals (test)\", \"lin_test_resid.png\")\n",
    "\n",
    "            imp = permutation_importance_light(mdl, X_test, y_test, feat_list, n_repeats=3, max_rows=500)\n",
    "            if imp is not None:\n",
    "                mlflow.log_text(imp.head(30).to_markdown(index=False), \"lin_perm_importance.md\")\n",
    "\n",
    "            # 동적 재귀 예측\n",
    "            df_fore = recursive_forecast_dynamic(df_feat, TARGET, feat_list, mdl, HORIZON)\n",
    "            path = OUTDIR / \"linear_forecast.csv\"\n",
    "            df_fore.to_csv(path, index=False); mlflow.log_artifact(str(path))\n",
    "            lineplot(df_fore[\"date\"], df_fore[\"yhat\"], \"Linear forecast (future)\", \"lin_forecast.png\")\n",
    "\n",
    "            try:\n",
    "                sig = mlflow.models.infer_signature(X_train[:5], mdl.predict(X_train[:5]))\n",
    "                if mlflow_sklearn is not None:\n",
    "                    mlflow_sklearn.log_model(sk_model=mdl, name=\"model_linear\",\n",
    "                                             signature=sig, input_example=X_train[:5],\n",
    "                                             pip_requirements=[\"mlflow\",\"scikit-learn\"])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # ---- 모델 2: RandomForest\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        with mlflow.start_run(run_name=\"model_rf\", nested=True):\n",
    "            params = {\"algo\":\"RandomForestRegressor\",\"n_estimators\":400,\"max_depth\":12,\"min_samples_leaf\":2,\n",
    "                      \"n_jobs\":-1,\"random_state\":42,\"horizon\":HORIZON,\"test_days\":TEST_DAYS,\n",
    "                      \"feat_count\":len(feat_list)}\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_input(train_ds, context=\"training\")\n",
    "            mlflow.log_input(test_ds,  context=\"testing\")\n",
    "\n",
    "            rf = RandomForestRegressor(\n",
    "                n_estimators=params[\"n_estimators\"],\n",
    "                max_depth=params[\"max_depth\"],\n",
    "                min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "                n_jobs=-1, random_state=42\n",
    "            )\n",
    "            rf.fit(X_train, y_train)\n",
    "            pred_test = rf.predict(X_test)\n",
    "            m = reg_metrics(y_test, pred_test)\n",
    "            mlflow.log_metrics({f\"test_{k}\":v for k,v in m.items()})\n",
    "\n",
    "            dt_test = test_df.loc[idx_test, \"date\"]\n",
    "            dualplot(dt_test, y_test, pred_test, \"RF: actual vs pred (test)\", \"rf_test_pred.png\")\n",
    "            residplot(y_test, pred_test, \"RF: residuals (test)\", \"rf_test_resid.png\")\n",
    "\n",
    "            imp = permutation_importance_light(rf, X_test, y_test, feat_list, n_repeats=3, max_rows=500)\n",
    "            if imp is not None:\n",
    "                mlflow.log_text(imp.head(30).to_markdown(index=False), \"rf_perm_importance.md\")\n",
    "\n",
    "            df_fore = recursive_forecast_dynamic(df_feat, TARGET, feat_list, rf, HORIZON)\n",
    "            path = OUTDIR / \"rf_forecast.csv\"\n",
    "            df_fore.to_csv(path, index=False); mlflow.log_artifact(str(path))\n",
    "            lineplot(df_fore[\"date\"], df_fore[\"yhat\"], \"RF forecast (future)\", \"rf_forecast.png\")\n",
    "\n",
    "            try:\n",
    "                sig = mlflow.models.infer_signature(X_train[:5], rf.predict(X_train[:5]))\n",
    "                if mlflow_sklearn is not None:\n",
    "                    mlflow_sklearn.log_model(sk_model=rf, name=\"model_rf\",\n",
    "                                             signature=sig, input_example=X_train[:5],\n",
    "                                             pip_requirements=[\"mlflow\",\"scikit-learn\"])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # ---- (선택) 모델 3: XGBoost (설치 시)\n",
    "        try:\n",
    "            from xgboost import XGBRegressor\n",
    "            with mlflow.start_run(run_name=\"model_xgb\", nested=True):\n",
    "                params = {\"algo\":\"XGBRegressor\",\"n_estimators\":600,\"max_depth\":6,\"learning_rate\":0.05,\n",
    "                          \"subsample\":0.9,\"colsample_bytree\":0.9,\"random_state\":42,\n",
    "                          \"reg_lambda\":1.0,\"horizon\":HORIZON,\"test_days\":TEST_DAYS,\n",
    "                          \"feat_count\":len(feat_list)}\n",
    "                mlflow.log_params(params)\n",
    "                mlflow.log_input(train_ds, \"training\"); mlflow.log_input(test_ds, \"testing\")\n",
    "\n",
    "                xgb = XGBRegressor(\n",
    "                    n_estimators=params[\"n_estimators\"], max_depth=params[\"max_depth\"],\n",
    "                    learning_rate=params[\"learning_rate\"], subsample=params[\"subsample\"],\n",
    "                    colsample_bytree=params[\"colsample_bytree\"], random_state=42, n_jobs=-1,\n",
    "                    reg_lambda=params[\"reg_lambda\"], tree_method=\"hist\"\n",
    "                )\n",
    "                xgb.fit(X_train, y_train)\n",
    "                pred_test = xgb.predict(X_test)\n",
    "                m = reg_metrics(y_test, pred_test)\n",
    "                mlflow.log_metrics({f\"test_{k}\":v for k,v in m.items()})\n",
    "\n",
    "                dt_test = test_df.loc[idx_test, \"date\"]\n",
    "                dualplot(dt_test, y_test, pred_test, \"XGB: actual vs pred (test)\", \"xgb_test_pred.png\")\n",
    "                residplot(y_test, pred_test, \"XGB: residuals (test)\", \"xgb_test_resid.png\")\n",
    "\n",
    "                df_fore = recursive_forecast_dynamic(df_feat, TARGET, feat_list, xgb, HORIZON)\n",
    "                path = OUTDIR / \"xgb_forecast.csv\"\n",
    "                df_fore.to_csv(path, index=False); mlflow.log_artifact(str(path))\n",
    "                lineplot(df_fore[\"date\"], df_fore[\"yhat\"], \"XGB forecast (future)\", \"xgb_forecast.png\")\n",
    "\n",
    "                try:\n",
    "                    import mlflow.xgboost as mlflow_xgb\n",
    "                    sig = mlflow.models.infer_signature(X_train[:5], xgb.predict(X_train[:5]))\n",
    "                    mlflow_xgb.log_model(xgb, name=\"model_xgb\",\n",
    "                                         signature=sig, input_example=X_train[:5],\n",
    "                                         pip_requirements=[\"mlflow\",\"xgboost\"])\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass  # xgboost 미설치면 자동 스킵\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
